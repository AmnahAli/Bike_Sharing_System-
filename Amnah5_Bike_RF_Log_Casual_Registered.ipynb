{
 "metadata": {
  "name": "",
  "signature": "sha256:9be50de2f86d85fb52a68eda33ce0ac15b051b1c039a11d3618855d53b77cea9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Loading package and data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import math\n",
      " \n",
      "from sklearn import ensemble\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from datetime import datetime\n",
      " \n",
      "#Load Data with pandas, and parse the\n",
      "#first column into datetime\n",
      "train = pd.read_csv('train.csv', parse_dates=[0])\n",
      "test = pd.read_csv('test.csv', parse_dates=[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Feature engineering"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Feature engineering\n",
      "temp = pd.DatetimeIndex(train['datetime'])\n",
      "train['year'] = temp.year\n",
      "train['month'] = temp.month\n",
      "train['hour'] = temp.hour\n",
      "train['weekday'] = temp.weekday\n",
      " \n",
      "temp = pd.DatetimeIndex(test['datetime'])\n",
      "test['year'] = temp.year\n",
      "test['month'] = temp.month\n",
      "test['hour'] = temp.hour\n",
      "test['weekday'] = temp.weekday\n",
      " \n",
      "#Define features vector\n",
      "features = ['season', 'holiday', 'workingday', 'weather',\n",
      "        'temp', 'atemp', 'humidity', 'windspeed', 'year',\n",
      "         'month', 'weekday', 'hour']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train[features].head(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>season</th>\n",
        "      <th>holiday</th>\n",
        "      <th>workingday</th>\n",
        "      <th>weather</th>\n",
        "      <th>temp</th>\n",
        "      <th>atemp</th>\n",
        "      <th>humidity</th>\n",
        "      <th>windspeed</th>\n",
        "      <th>year</th>\n",
        "      <th>month</th>\n",
        "      <th>weekday</th>\n",
        "      <th>hour</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 9.84</td>\n",
        "      <td> 14.395</td>\n",
        "      <td> 81</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2011</td>\n",
        "      <td> 1</td>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>1 rows \u00d7 12 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "   season  holiday  workingday  weather  temp   atemp  humidity  windspeed  \\\n",
        "0       1        0           0        1  9.84  14.395        81          0   \n",
        "\n",
        "   year  month  weekday  hour  \n",
        "0  2011      1        5     0  \n",
        "\n",
        "[1 rows x 12 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Evaluation metric"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#the evaluation metric is the RMSE in the log domain,\n",
      "#so we should transform the target columns into log domain as well. instred of log10(x+1)\n",
      "for col in ['casual', 'registered', 'counts']:\n",
      "    train['log-count'] = train['counts'].apply(lambda x: np.log1p(x))      \n",
      "    train['log-casual'] = train['registered'].apply(lambda x: np.log1p(x))\n",
      "    train['log-registered'] = train['casual'].apply(lambda x: np.log1p(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Model development\n",
      "#A first pass "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 200 , 3\n",
      "clf = ensemble.RandomForestRegressor(n_estimators = 100)\n",
      "clf.fit(train[features], train['log-count'])\n",
      "result = clf.predict(test[features])\n",
      "result = np.expm1(result)\n",
      " \n",
      "df=pd.DataFrame({'datetime':test['datetime'], 'count':result})\n",
      "df.to_csv('RF1.csv', index = False, columns=['datetime','count'])  #Kaggle 0.41661 , 404 this one for GBR\n",
      "#Kaggle  0.44099, 762"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Hyperparameter tuning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Split data into training and validation sets <16,   >16, 500 ,  4\n",
      "temp = pd.DatetimeIndex(train['datetime'])\n",
      "training = train[temp.day <= 19]\n",
      "validation = train[temp.day > 19]\n",
      " \n",
      "param_grid = {\n",
      "              'max_depth': [10, 15, 20],\n",
      "              'min_samples_leaf': [3, 5, 10, 20],\n",
      "              }\n",
      " \n",
      "est = ensemble.RandomForestRegressor(n_estimators = 100)\n",
      "# this may take awhile\n",
      "gs_cv = GridSearchCV(est, param_grid, n_jobs=3).fit(\n",
      "    training[features], training['log-count'])\n",
      " \n",
      "# best hyperparameter setting\n",
      "gs_cv.best_params_\n",
      " \n",
      "#Baseline error\n",
      "#error_count = mean_absolute_error(validation['log-count'], gs_cv.predict(validation[features]))  #???!!!!\n",
      " \n",
      "result = gs_cv.predict(test[features])\n",
      "result = np.expm1(result)\n",
      "df=pd.DataFrame({'datetime':test['datetime'], 'count':result})\n",
      "df.to_csv('RF2.csv', index = False, columns=['datetime','count'])  # 19, Kaggle 0.42726, 541\n",
      "#16, Kaggle 0.43659, 726 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Tuning the number of estimators     "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "error_train=[]\n",
      "error_validation=[]\n",
      "for k in range(10, 501, 10):\n",
      "    clf = ensemble.RandomForestRegressor(n_estimators=k, max_depth = 10,min_samples_leaf = 20)\n",
      " \n",
      "    clf.fit(training[features], training['log-count'])\n",
      "    result = clf.predict(training[features])\n",
      "    error_train.append(mean_absolute_error(result, training['log-count']))\n",
      " \n",
      "    result = clf.predict(validation[features])\n",
      "    error_validation.append(mean_absolute_error(result, validation['log-count']))        \n",
      " \n",
      "#Plot the data\n",
      "x=range(10,501, 10)\n",
      "#plt.style.use('ggplot')\n",
      "#plt.ggplot(x, error_train, 'k')  #plot\n",
      "plt.plot(x, error_validation, 'b')\n",
      "plt.xlabel('Number of Estimators', fontsize=18)\n",
      "plt.ylabel('Error', fontsize=18)\n",
      "plt.legend(['Train', 'Validation'], fontsize=18)\n",
      "plt.title('Error vs. Number of Estimators', fontsize=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Found array with 0 sample(s) (shape=(0, 12)) while a minimum of 1 is required.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-a665c1ebaa28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0merror_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log-count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0merror_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log-count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/aamnah/.local/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    619\u001b[0m                             X.indptr.dtype != np.intc):\n",
        "\u001b[0;32m/home/aamnah/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[1;32m    358\u001b[0m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[1;32m    359\u001b[0m                              \u001b[0;34m\" minimum of %d is required.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                              % (n_samples, shape_repr, ensure_min_samples))\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 12)) while a minimum of 1 is required."
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Separate models for registered and casual users"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def merge_predict(model1, model2, test_data):\n",
      "#    Combine the predictions of two separately trained models.\n",
      "#    The input models are in the log domain and returns the predictions\n",
      "#    in original domain.\n",
      "    p1 = np.expm1(model1.predict(test_data))\n",
      "    p2 = np.expm1(model2.predict(test_data))\n",
      "    p_total = (p1+p2)\n",
      "    return(p_total)\n",
      "est_casual = ensemble.RandomForestRegressor(n_estimators = 500)    # 80, .05\n",
      "est_registered = ensemble.RandomForestRegressor(n_estimators = 500)\n",
      "param_grid2 = {'max_depth': [10, 15, 20],\n",
      "              'min_samples_leaf': [3, 5, 10, 20],\n",
      "              }\n",
      " \n",
      "gs_casual = GridSearchCV(est_casual, param_grid2, n_jobs=4).fit(training[features], training['log-casual'])\n",
      "gs_registered = GridSearchCV(est_registered, param_grid2, n_jobs=4).fit(training[features], training['log-registered'])      \n",
      " \n",
      "result3 = merge_predict(gs_casual, gs_registered, test[features])\n",
      "df=pd.DataFrame({'datetime':test['datetime'], 'count':result3})\n",
      "df.to_csv('RF3.csv', index = False, columns=['datetime','count'])  #Kaggle  1.28286 ,2953 GBR\n",
      "#Kaggle  \t0.84380 , 2671"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#<pre>\n",
      "est_casual = ensemble.RandomForestRegressor(n_estimators = 500, max_depth = 10,min_samples_leaf = 20)      #80,.05, 10, 20\n",
      "est_registered = ensemble.RandomForestRegressor(n_estimators = 500, max_depth = 10,min_samples_leaf = 20)\n",
      " \n",
      "est_casual.fit(train[features].values, train['log-casual'].values)\n",
      "est_registered.fit(train[features].values, train['log-registered'].values)\n",
      "result4 = merge_predict(est_casual, est_registered, test[features])\n",
      " \n",
      "df=pd.DataFrame({'datetime':test['datetime'], 'count':result4})\n",
      "df.to_csv('RF4.csv', index = False, columns=['datetime','count']) # Kaggle 0.42163 , 475 GBR\n",
      "#Kaggel  \t0.86529 \t, 2696"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'features' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-3d6f789135db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mest_registered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mest_casual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log-casual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mest_registered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log-registered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mresult4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_casual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_registered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}